{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c78dbc",
   "metadata": {},
   "source": [
    "# Import Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f53a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbba9db",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aae08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cf45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('UpdatedResumeDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db944b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9324f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only the required columns and rename 'Resume_str' to 'Resume'\n",
    "df = df1[['Category', 'Resume_str']].rename(columns={'Resume_str': 'Resume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e6702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e657af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.merge(df, df2, on='Category', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e09a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat([df, df2],ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('newCSV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101597f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the updated DataFrame\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49742c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035028b",
   "metadata": {},
   "source": [
    "# Exploring Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Category', data=DF)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = DF['Category'].value_counts()\n",
    "labels = DF['Category'].unique()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', shadow = True, colors = plt.cm.plasma(np.linspace(0,1,3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e63fc",
   "metadata": {},
   "source": [
    "# Exploring Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb13722",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb595a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Category'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Resume'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0781e7",
   "metadata": {},
   "source": [
    "# Balance Classes (Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the original category distribution\n",
    "print(\"Original Category Distribution:\")\n",
    "print(DF['Category'].value_counts())\n",
    "\n",
    "# Get the largest category size (i.e., the category with the maximum number of entries)\n",
    "max_size = DF['Category'].value_counts().max()\n",
    "\n",
    "# Perform oversampling\n",
    "balanced_DF = DF.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the dataset to avoid any order bias\n",
    "DF = balanced_DF.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check the balanced category distribution\n",
    "print(\"\\nBalanced Category Distribution (After Oversampling):\")\n",
    "print(DF['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d178b",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "      Url's\n",
    "      hashtags\n",
    "      mentions\n",
    "      special letters\n",
    "      punctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)  \n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanResume(\"my #### $ #  #noorsaeed webiste like is this http://heloword and access it @gmain.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.columns = DF.columns.str.strip()  # Removes leading/trailing spaces\n",
    "DF.columns = DF.columns.str.lower()  # Makes all columns lowercase\n",
    "print(DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36769a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF['resume'] = DF['resume'].apply(lambda x: cleanResume(x))  #  correct after lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0127f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['resume'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['resume'] [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1d97d",
   "metadata": {},
   "source": [
    "# Words into categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(DF['category'])\n",
    "DF['category'] = le.transform(DF['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be690991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb7ab8",
   "metadata": {},
   "source": [
    "# Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words ='english')\n",
    "\n",
    "\n",
    "tfidf.fit(DF['resume'])\n",
    "requredTaxt = tfidf.transform(DF['resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e967a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "requredTaxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e74563",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36083e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(requredTaxt,DF['category'] , test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ae006",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca4197",
   "metadata": {},
   "source": [
    "# Now let's train the model and print the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "ypred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437896b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train RandomForestClassifier\n",
    "rf_model = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\nRandomForestClassifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaea090",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
    "pickle.dump(svc_model, open('clf.pkl', 'wb'))\n",
    "pickle.dump(le, open(\"encoder.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658ccf5",
   "metadata": {},
   "source": [
    "# Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86574e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the category of a resume\n",
    "def pred(input_resume):\n",
    "    # Preprocess the input text (e.g., cleaning, etc.)\n",
    "    cleaned_text = cleanResume(input_resume) \n",
    "\n",
    "    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training\n",
    "    vectorized_text = tfidf.transform([cleaned_text])\n",
    "    \n",
    "    # Convert sparse matrix to dense\n",
    "    vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "    # Prediction\n",
    "    predicted_category = clf.predict(vectorized_text)\n",
    "\n",
    "    # get name of predicted category\n",
    "    predicted_category_name = le.inverse_transform(predicted_category)\n",
    "\n",
    "    return predicted_category_name[0]  # Return the category name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258efe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b5115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
